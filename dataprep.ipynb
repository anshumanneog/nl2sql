{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_q = \"\"\"{\"phase\":1,\"question\":\"Find the Distinct count of games for RPG genre\",\"sql\":{\"conds\":[[8,0,\"RPG\"]],\"sel\":4,\"agg\":6},\"table_id\":\"1-9132139-1\"}\n",
    "{\"phase\":1,\"question\":\"how many distinct games for RPG genre\",\"sql\":{\"conds\":[[8,0,\"RPG\"]],\"sel\":4,\"agg\":6},\"table_id\":\"1-9132139-1\"}\n",
    "{\"phase\":1,\"question\":\"find total games for FPA genre\",\"sql\":{\"conds\":[[8,0,\"FPA\"]],\"sel\":4,\"agg\":3},\"table_id\":\"1-9132139-1\"}\n",
    "{\"phase\":1,\"question\":\"find distinct number of games for RPG genre\",\"sql\":{\"conds\":[[8,0,\"RPG\"]],\"sel\":4,\"agg\":6},\"table_id\":\"1-9132139-1\"}\n",
    "{\"phase\":1,\"question\":\"FIND TOTAL primary playtime in seconds FOR GAME_NAME_ID = 123456\",\"sql\":{\"conds\":[[3,0,\"123456\"]],\"sel\":23,\"agg\":4},\"table_id\":\"1-9132138-1\"}\n",
    "{\"phase\":1,\"question\":\"FIND TOTAL NUMBER OF ACCOUNTS WHO PLAYED ON DATE = 11/20/2018\",\"sql\":{\"conds\":[[1,0,\"11/20/2018\"]],\"sel\":20,\"agg\":3},\"table_id\":\"1-9132138-1\"}\n",
    "{\"phase\":1,\"question\":\"Find the Number of games under franchise 125690\",\"sql\":{\"conds\":[[2,0,\"125690\"]],\"sel\":4,\"agg\":3},\"table_id\":\"1-9132139-1\"}\n",
    "{\"phase\":1,\"question\":\"Find the number of distinct Title_ID for Horizon Zero Dawn\",\"sql\":{\"conds\":[[4,0,\"Horizon Zero Dawn\"]],\"sel\":0,\"agg\":6},\"table_id\":\"1-9132139-1\"}\"\"\".split('\\n')\n",
    "extra_col = \"\"\"{\"id\":\"1-9132139-1\",\"header\":['TITLE_ID','FRANCHISE_NAME_ID','FRANCHISE_NAME','GAME_NAME_ID','GAME_NAME','SUPER_TITLE_NAME_ID','SUPER_TITLE_NAME','GAME_GENRE_ID','GAME_GENRE','PARTY_TYPE_ID','PARTY_TYPE','GLOBAL_SERVICE_PROVIDER_ID','GLOBAL_SERVICE_PROVIDER_ID_ID','GLOBAL_SERVICE_PROVIDER_NAME','GLOBAL_TITLE_ID','GLOBAL_TITLE_ID_ID','GLOBAL_TITLE_NAME','PMT_SERVICE_PROVIDER_ID_ID','PMT_SERVICE_PROVIDER_ID','PMT_SERVICE_PROVIDER_NAME','PMT_SERVICE_PROVIDER_JP_NAME','TITLE_NAME','SALES_TITLE_ID','SALES_TITLE','SALES_FRANCHISE_ID','SALES_FRANCHISE','PMT_TITLE_NAME','PMT_TITLE_JP_NAME','DISK_TITLE_NAME','TMDB_TITLE_NAME','ADOBE_RECOMMENDATIONS_FRANCHISE_NAME_ID','ADOBE_RECOMMENDATIONS_FRANCHISE_NAME','ADOBE_RECOMMENDATIONS_TITLE_NAME_ID','ADOBE_RECOMMENDATIONS_TITLE_NAME','TITLE_TYPE','TITLE_TYPE_ID','TITLE_TYPE_LEVEL_2','TITLE_TYPE_LEVEL_2_ID','TITLE_TYPE_LEVEL_3','TITLE_TYPE_LEVEL_3_ID','PLUGIN_IND','PLUGIN_GROUP_ID','PLUGIN_GROUP','MOVE_EXCLUSIVE_IND','TITLE_ATTRIBUTE_OVERRIDE_SET','SCEA_TITLE_RELEASE_RHQ_DT','SCEE_TITLE_RELEASE_RHQ_DT','SCEJ_TITLE_RELEASE_RHQ_DT','SCEASIA_TITLE_RELEASE_RHQ_DT','SCEA_GAME_RELEASE_RHQ_DT','SCEE_GAME_RELEASE_RHQ_DT','SCEJ_GAME_RELEASE_RHQ_DT','SCEASIA_GAME_RELEASE_RHQ_DT','PMT_TITLE_NAME_LONG','PMT_TITLE_NAME_ORIGINAL','PMT_TITLE_NAME_CLEANSED_IND','UNITY_TITLE_NAME','UNITY_TITLE_NAME_ID','UNITY_PUBLISHING_MODEL','UNITY_PUBLISHING_MODEL_ID','TITLE_PUBLISHER_TYPE','TITLE_DISTRIBUTION_REGION','TITLE_TARGET_CONSOLE_GENERATION','TITLE_ORIGINAL_CONSOLE_GENERATION','TITLE_MEDIA_TYPE','GAME_MEDIA_TYPE','TITLE_CONTENT_SUB_TYPE','TITLE_CONTENT_TYPE','MULTI_DISC_IND','SOURCE_TITLE_ID','SOURCE_SYSTEM_ID','ETL_ID_INSERTED','ETL_ID_UPDATED']}\n",
    "{\"id\":\"1-9132138-1\",\"header\":['GAME_PLAY_SESSION_ID','SESSION_START_UTC_DTTM','SESSION_START_UTC_DT_ID','SESSION_START_RHQ_DT_ID','SESSION_START_LOCATION_DT_ID','SESSION_START_UTC_TIME_ID','SESSION_START_LOCATION_TIME_ID','DEVICE_ID','DEVICE_TYPE_ID','IP_GEO_LOCATION_ID','SESSION_START_ACCT_ID','SESSION_START_ACCT_SCE_REGION_ID','SESSION_START_ACCT_COUNTRY_ISO_CODE','TITLE_ID','MEDIA_ID','SESSION_TYPE_ID','APPLICATION_VERSION_ID','FIRMWARE_VERSION_ID','GAME_PLAY_SESSION_CHARACTERISTICS_ID','GAME_PLAY_CHARACTERISTICS_ID','PRIMARY_ACCT_ID','PRIMARY_ACCT_SCE_REGION_ID','PRIMARY_ACCT_COUNTRY_ISO_CODE','PRIMARY_SESSION_LENGTH_SECONDS','SESSION_LENGTH_SECONDS','PSN_ACCOUNTS','LOCAL_ACCOUNTS','CONNECTED_DS4S','SECONDARY_GAMEPLAY_IND','LOCAL_GAMEPLAY_IND','SESSION_LENGTH_DEFAULTED_IND','SOURCE_SYSTEM_ID','ETL_ID_INSERTED']}\"\"\".replace(\"\\'\", '\\\"').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.loads(extra_col[0])['header'][8]#.index('FRANCHISE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import re\n",
    "import json, pandas as pd\n",
    "import numpy as np\n",
    "from lib.query import Query\n",
    "import torch\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score \n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow\n",
    "import keras\n",
    "import re\n",
    "import json, pandas as pd\n",
    "import numpy as np\n",
    "# from lib.query import Query\n",
    "import torch\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query.agg_ops = ['', 'MAX', 'MIN', 'COUNT', 'SUM', 'AVG', 'COUNT_DISTINCT']\n",
    "class load_data:\n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "\n",
    "def inject_table_names(sql, table_cols):\n",
    "    \"\"\"\n",
    "    replace col<index> in `sql` query with the <column_name> from `table_cols`\n",
    "    \"\"\"\n",
    "    try:\n",
    "        regex = re.compile(r'\\scol(\\d+)')\n",
    "        return regex.sub(lambda x: ' ' + table_cols[int(x.string[x.start()+4: x.end()])],  str(sql))\n",
    "    except Exception as e:\n",
    "        print(e, sql, table_cols)\n",
    "#         pass\n",
    "    return None\n",
    "# def clean_text(text):\n",
    "#     return \n",
    "#     text = re.sub('\\W+', ' ', text)\n",
    "#     return text\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filepath_phrase, filepath_table):\n",
    "    \n",
    "    lines = open(filepath_phrase, 'r').readlines()\n",
    "    lines += extra_q\n",
    "    df_phrases = pd.DataFrame([json.loads(line) for line in lines])\n",
    "    lines = open(filepath_table, 'r').readlines()\n",
    "    lines +=extra_col\n",
    "    df_tables = pd.DataFrame([json.loads(line) for line in lines])\n",
    "    # join table data with sql data\n",
    "    df = pd.merge(df_phrases, df_tables[['id', 'header']], left_on='table_id', right_on='id')\n",
    "#     df= df[:10000]\n",
    "    df['query_temp'] = df.sql.apply(lambda data: Query.from_dict(d=data))\n",
    "    df['query'] = df.loc[:, ['query_temp', 'header']]\\\n",
    "        .apply(lambda row: inject_table_names(row[0], row[1]), axis=1)\n",
    "    df['agg'] = df['sql'].apply(lambda x: x['agg'])\n",
    "    df['sel_col'] = df['sql'].apply(lambda x: x['sel'])\n",
    "    \n",
    "#     questions = df['question'].apply(clean_text).values\n",
    "    questions = df['question'].values\n",
    "    queries = df['query'].values\n",
    "    column_names = df['header'].values\n",
    "    agg = df['agg'].values\n",
    "    sel_col = df['sel_col'].values\n",
    "    return questions, queries, column_names, df, agg, sel_col \n",
    "\n",
    "train_questions, train_queries, train_column_names, df_train, train_agg, train_sel_col,  = load_data('data/train.jsonl', 'data/train.tables.jsonl')\n",
    "test_questions, test_queries, test_column_names, df_test, test_agg, test_sel_col = load_data('data/test.jsonl', 'data/test.tables.jsonl')\n",
    "dev_questions, dev_queries, dev_column_names, _, dev_agg, dev_sel_col = load_data('data/dev.jsonl', 'data/dev.tables.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[:1000]\n",
    "# df_test = df_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['', 'MAX', 'MIN', 'COUNT', 'SUM', 'AVG', 'COUNT_DISTINCT'],\n",
       " ['=', '>', '<', 'OP'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_ops = Query.agg_ops\n",
    "cond_ops = Query.cond_ops\n",
    "len(agg_ops)\n",
    "agg_ops, cond_ops\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    :param questions: list of questions\n",
    "    :param headers: list of list of column names corresponding to the questions list\n",
    "    :param sql_dicts: list of sql dictionary corresponding to the question list\n",
    "    :param ops: list of ordered conditional operations s.t. ops at index i corresponds to the condops in sql_dict\n",
    "    :param agg: list of aggeration operations s.t. agg at index i should correspond to the agg in sql_dict\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, questions, header, sql_dict, ops, agg,\n",
    "                 embedding_filepath='data/glove.42B.300d.txt',\n",
    "                 max_words_per_question_percentile=99,\n",
    "                 max_words_per_column_percentile=99,\n",
    "                 max_columns_per_table_percentile=100):\n",
    "\n",
    "        self.ops = ops\n",
    "        self.agg = agg\n",
    "        self.n_ops = len(ops)\n",
    "        self.n_agg = len(agg)\n",
    "\n",
    "        self.max_words_per_question_percentile = max_words_per_question_percentile\n",
    "        self.max_words_per_column_percentile = max_words_per_column_percentile\n",
    "        self.max_columns_per_table_percentile = max_columns_per_table_percentile\n",
    "        self.lmtzr = WordNetLemmatizer()\n",
    "\n",
    "        self.embedding_filepath = embedding_filepath\n",
    "        self._fit(questions, header)\n",
    "        self._initilize_index_of_seq()\n",
    "\n",
    "        self.states_index = {'start': 0,\n",
    "                             'agg': 1,\n",
    "                             'selcol': 2,\n",
    "                             'condcol': 3,\n",
    "                             'condop': 4,\n",
    "                             'condval': 5,\n",
    "                             'end': 6}\n",
    "\n",
    "        self.question_padding = 'pre'\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        #         doc = nlp(text)\n",
    "        #         text = ' '.join([token.lemma_ for token in doc])\n",
    "        #         text = re.sub('\\W+', ' ', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub('\\d+', 'NUMTAG', text)\n",
    "        text = re.sub('=', ' equal to ', text)\n",
    "        text = re.sub('<', '  less than ', text)\n",
    "        text = re.sub('>', ' greater than ', text)\n",
    "        text = ' '.join(list(map(self.lmtzr.lemmatize, word_tokenize(text))))\n",
    "#         text = re.sub('[\\s]\\W+[\\s]', 'SYMNUM', text)\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def get_embedding_matrix(filepath, word_index):\n",
    "        embeddings_index = {}\n",
    "        EMBEDDING_DIM = int(re.findall(('(?<=\\.)\\d+(?=d)'), filepath)[0])\n",
    "        f = open(filepath)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "\n",
    "        print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "        embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "        for word, i in word_index.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "            else:\n",
    "                #         print(\"Not Found in Embedding Matrix: \", word)\n",
    "                pass\n",
    "        return embedding_matrix\n",
    "\n",
    "    def _fit(self, questions, headers):\n",
    "\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.tokenizer.fit_on_texts(list(map(self.clean_text, questions)) + [y for x in headers for y in x])\n",
    "        #         self.tokenizer.fit_on_texts(list(questions) + [y for x in headers for y in x])\n",
    "        question_sequences = self.tokenizer.texts_to_sequences(questions)\n",
    "        columns_sequences = [self.tokenizer.texts_to_sequences(columns) for columns in headers]\n",
    "\n",
    "        self.max_words_per_question = int(np.percentile(list(map(lambda x: len(x), question_sequences)),\n",
    "                                                        self.max_words_per_question_percentile))\n",
    "\n",
    "        self.max_words_per_column = int(np.percentile([len(col) for col_list in columns_sequences for col in col_list],\n",
    "                                                      self.max_words_per_column_percentile))\n",
    "\n",
    "        self.max_columns_per_table = int(np.percentile([len(col_list) for col_list in columns_sequences],\n",
    "                                                       self.max_columns_per_table_percentile))\n",
    "\n",
    "        self.embedding_matrix = DataTransformer.get_embedding_matrix(self.embedding_filepath, self.tokenizer.word_index)\n",
    "        return self\n",
    "\n",
    "    def transform_questions(self, questions):\n",
    "\n",
    "        question_sequences = self.tokenizer.texts_to_sequences(list(map(self.clean_text, questions)))\n",
    "        #         question_sequences = self.tokenizer.texts_to_sequences(list(questions))\n",
    "        question_sequences = pad_sequences(question_sequences, maxlen=self.max_words_per_question, padding='pre',\n",
    "                                           truncating='post')\n",
    "        return question_sequences\n",
    "\n",
    "    def transform_columns(self, columns):\n",
    "        columns_sequences = [self.tokenizer.texts_to_sequences(columns_per_table) for columns_per_table in columns]\n",
    "        columns_sequences = [pad_sequences(column_list, maxlen=self.max_words_per_column) for column_list in\n",
    "                             columns_sequences]\n",
    "        columns_sequences = DataTransformer.pad_columns(columns_sequences, maxlen=self.max_columns_per_table,\n",
    "                                                        truncating='post', padding='post')\n",
    "        return columns_sequences\n",
    "\n",
    "    def ohe_agg(self, aggs):\n",
    "        #         sel_col_ohe = np.zeros(max_columns_per_table)\n",
    "        ohe_vector = np.zeros((len(aggs), self.n_agg))\n",
    "        ohe_vector[np.arange(len(aggs)), aggs] = 1\n",
    "        return ohe_vector\n",
    "\n",
    "    def ohe_column(self, columns):\n",
    "        ohe_vector = np.zeros((len(columns), self.max_columns_per_table))\n",
    "        ohe_vector[np.arange(len(columns)), columns] = 1\n",
    "        return ohe_vector\n",
    "\n",
    "    def ohe_ops(self, ops):\n",
    "        ohe_vector = np.zeros((len(ops), self.n_ops))\n",
    "        ohe_vector[np.arange(len(ops)), ops] = 1\n",
    "        return ohe_vector\n",
    "\n",
    "    def _transform_conds(self, conditions):\n",
    "        conditions = list(map(lambda x: self.clean_text(str(x)), conditions))\n",
    "        return self.tokenizer.texts_to_sequences(conditions)\n",
    "\n",
    "    def get_condition_seq(self, conds, questions):\n",
    "        def find_start_end_index(masked):\n",
    "            seq = ''.join(map(str, masked))\n",
    "            ones_seq = re.findall('1+', seq)\n",
    "            if not ones_seq:\n",
    "                return None, None\n",
    "            cond_seq = max(ones_seq, key=len)\n",
    "            start_index = seq.index(cond_seq)\n",
    "            end_index = start_index + len(cond_seq) - 1\n",
    "            return start_index, end_index\n",
    "\n",
    "        #         zipped = zip(self._transform_conds(conds), self.transform_questions(questions))\n",
    "        masked = list(map(lambda cond, question: np.in1d(question, cond).astype(np.int),\n",
    "                          self._transform_conds(conds), self.transform_questions(questions)))\n",
    "        #         print(conds, questions)\n",
    "        start_end_indices = np.array(list(map(find_start_end_index, masked)))\n",
    "        start_seq, end_seq = np.zeros((len(questions), self.max_words_per_question)), np.zeros(\n",
    "            (len(questions), self.max_words_per_question))\n",
    "\n",
    "        for row, col in enumerate(start_end_indices[:, 0]):\n",
    "            if col:\n",
    "                start_seq[row, col] = 1\n",
    "        for row, col in enumerate(start_end_indices[:, 1]):\n",
    "            if col:\n",
    "                end_seq[row, col] = 1\n",
    "\n",
    "        return masked, start_seq, end_seq\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_columns(list_of_list_cols, maxlen, dtype='int32', padding='post', truncating='post', value=0.0):\n",
    "\n",
    "        def _pad_columns(sequences, maxlen, dtype, padding, truncating, value):\n",
    "            diff = maxlen - len(sequences)\n",
    "            len_of_each_seq = len(sequences[0])\n",
    "            if diff > 0:\n",
    "                if padding == 'pre':\n",
    "                    return np.full(shape=(diff, len_of_each_seq), fill_value=value, dtype=dtype).tolist() + list(\n",
    "                        sequences)\n",
    "                else:\n",
    "                    return list(sequences) + np.full(shape=(diff, len_of_each_seq), fill_value=value,\n",
    "                                                     dtype=dtype).tolist()\n",
    "            elif diff < 0:\n",
    "                if truncating == 'pre':\n",
    "                    return list(sequences[-diff:])\n",
    "                else:\n",
    "                    return list(sequences[:maxlen])\n",
    "            return list(sequences)\n",
    "\n",
    "        return np.array([_pad_columns(list_, maxlen, dtype, padding, truncating, value) for list_ in list_of_list_cols])\n",
    "\n",
    "    def _initilize_index_of_seq(self):\n",
    "\n",
    "        self.start_index = np.arange(0, 1)\n",
    "\n",
    "        self.agg_index = np.arange(1, self.n_agg + 1)\n",
    "\n",
    "        self.sel_index = np.arange(self.n_agg + 1, self.n_agg +\n",
    "                                   self.max_columns_per_table + 1)\n",
    "        self.concol_index = np.arange(self.n_agg +\n",
    "                                      self.max_columns_per_table + 1, self.n_agg +\n",
    "                                      self.max_columns_per_table +\n",
    "                                      self.max_columns_per_table + 1)\n",
    "        self.conops_index = np.arange(self.n_agg +\n",
    "                                      self.max_columns_per_table +\n",
    "                                      self.max_columns_per_table + 1, self.n_agg +\n",
    "                                      self.max_columns_per_table +\n",
    "                                      self.max_columns_per_table +\n",
    "                                      self.n_ops + 1)\n",
    "        self.condval_index = np.arange(self.n_agg +\n",
    "                                       self.max_columns_per_table +\n",
    "                                       self.max_columns_per_table +\n",
    "                                       self.n_ops + 1, self.n_agg +\n",
    "                                       self.max_columns_per_table +\n",
    "                                       self.max_columns_per_table +\n",
    "                                       self.n_ops +\n",
    "                                       self.max_words_per_question + 1)\n",
    "        self.end_index = np.arange(self.n_agg +\n",
    "                                   self.max_columns_per_table +\n",
    "                                   self.max_columns_per_table +\n",
    "                                   self.n_ops +\n",
    "                                   self.max_words_per_question + 1,\n",
    "                                   self.n_agg +\n",
    "                                   self.max_columns_per_table +\n",
    "                                   self.max_columns_per_table +\n",
    "                                   self.n_ops +\n",
    "                                   self.max_words_per_question + 2)\n",
    "\n",
    "        self.action_index = {'start': self.start_index,\n",
    "                             'agg': self.agg_index,\n",
    "                             'selcol': self.sel_index,\n",
    "                             'condcol': self.concol_index,\n",
    "                             'condops': self.conops_index,\n",
    "                             'condval': self.condval_index,\n",
    "                             'end': self.end_index}\n",
    "        return self.action_index\n",
    "        #         self.agg_index = np.arange(0, self.n_agg)\n",
    "        #         self.sel_index = np.arange(self.n_agg, self.n_agg +\n",
    "        #                                    self.max_columns_per_table)\n",
    "        #         self.concol_index = np.arange(self.n_agg +\n",
    "        #                                       self.max_columns_per_table, self.n_agg +\n",
    "        #                                       self.max_columns_per_table +\n",
    "        #                                       self.max_columns_per_table)\n",
    "        #         self.conops_index = np.arange(self.n_agg +\n",
    "        #                                       self.max_columns_per_table +\n",
    "        #                                       self.max_columns_per_table, self.n_agg +\n",
    "        #                                       self.max_columns_per_table +\n",
    "        #                                       self.max_columns_per_table +\n",
    "        #                                       self.n_ops)\n",
    "        #         self.condval_index = np.arange(self.n_agg +\n",
    "        #                                        self.max_columns_per_table +\n",
    "        #                                        self.max_columns_per_table +\n",
    "        #                                        self.n_ops, self.n_agg +\n",
    "        #                                        self.max_columns_per_table +\n",
    "        #                                        self.max_columns_per_table +\n",
    "        #                                        self.n_ops +\n",
    "        #                                        self.max_words_per_question)\n",
    "\n",
    "        return self\n",
    "\n",
    "    #     def tot_\n",
    "\n",
    "    def reverse_label_sequence(self, seqs, threshold=0.5, questions=None):\n",
    "\n",
    "        return list(map(lambda seq,\n",
    "                               question: [self._reverse_label_sequence(one_seq, question) for one_seq in seq],\n",
    "                        seqs,\n",
    "                        questions))\n",
    "\n",
    "    #     def _pad(self, seq, max_len, pre=True):\n",
    "    def _normalize_question_index(self, index, question_len):\n",
    "\n",
    "        if self.question_padding == 'pre':\n",
    "            # this won't work on truncated question\n",
    "            #             return list(map(lambda x: x - self.max_words_per_question + question_len, indices))\n",
    "            return index - self.max_words_per_question + question_len\n",
    "        if self.question_padding == 'post':\n",
    "            return index\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_unconsecutive_indices(indices):\n",
    "        if indices and len(indices) > 1:\n",
    "            return [indices[i] for i in range(len(indices) - 1) if indices[i] == indices[i + 1] - 1] + [indices[-1]]\n",
    "        return indices\n",
    "\n",
    "    def _reverse_label_sequence(self, seq, question=None):\n",
    "\n",
    "        seq = np.array(seq)\n",
    "        index = np.argmax(seq)\n",
    "        #         print(index)\n",
    "        if index in self.start_index:\n",
    "            return None, 0\n",
    "\n",
    "        if index in self.agg_index:\n",
    "            agg_seq = seq[self.agg_index]\n",
    "            agg = np.argmax(agg_seq)\n",
    "            state = 1\n",
    "            return agg, state\n",
    "\n",
    "        elif index in self.sel_index:\n",
    "            sel_seq = seq[self.sel_index]\n",
    "            sel = np.argmax(sel_seq)\n",
    "            state = 2\n",
    "            return sel, state\n",
    "\n",
    "        elif index in self.concol_index:\n",
    "            condcol_seq = seq[self.concol_index]\n",
    "            condcol = np.argmax(condcol_seq)\n",
    "            state = 3\n",
    "            return condcol, state\n",
    "\n",
    "        elif index in self.conops_index:\n",
    "            condop_seq = seq[self.conops_index]\n",
    "            condop = np.argmax(condop_seq)\n",
    "            state = 4\n",
    "            return condop, state\n",
    "\n",
    "        elif index in self.condval_index:\n",
    "            condval_seq = seq[self.condval_index]\n",
    "            condval_index = np.argmax(condval_seq)\n",
    "\n",
    "            condval = None\n",
    "            if question:\n",
    "                question_words = text_to_word_sequence(question,\n",
    "                                                       filters=self.tokenizer.filters,\n",
    "                                                       split=self.tokenizer.split,\n",
    "                                                       lower=self.tokenizer.lower)\n",
    "                #                 print(condval_index, question_words)\n",
    "\n",
    "                condval_index = self._normalize_question_index(condval_index, len(question_words))\n",
    "                #                 print(condval_index, question_words)\n",
    "                condval = question_words[condval_index]\n",
    "\n",
    "            state = 5\n",
    "            return condval if condval else condval_index, state\n",
    "\n",
    "        elif index in self.end_index:\n",
    "            return None, 6\n",
    "\n",
    "        #             condval = np.argwhere(condval_seq > threshold).squeeze()\n",
    "        #             if question is not None:\n",
    "\n",
    "        #                 question_words = text_to_word_sequence(question,\n",
    "        #                                                     filters=self.tokenizer.filters,\n",
    "        #                                                     split=self.tokenizer.split,\n",
    "        #                                                     lower=self.tokenizer.lower)\n",
    "        #                 if not hasattr(condval.tolist(), '__iter__'):\n",
    "        #                     condval = [condval]\n",
    "        # #                 print(question_words, condval, hasattr(condval, '__iter__'), list(condval))\n",
    "        # #                 print(condval, question_words)\n",
    "        #                 condval = self._normalize_question_index(condval, len(question_words))\n",
    "        #                 condval = DataTransformer._remove_unconsecutive_indices(condval)\n",
    "\n",
    "        #                 condvalwords = np.array(question_words)[condval]\n",
    "        #                 condval = ' '.join(condvalwords)\n",
    "\n",
    "        #             state = 5\n",
    "        #             return condval, state\n",
    "\n",
    "        return\n",
    "\n",
    "    def pad_label_sequence(self, targets):\n",
    "\n",
    "        def pad(x):\n",
    "            #         print(max_len)\n",
    "            n_pads = max_len - x.shape[0]\n",
    "            #         print(n_pads, x.shape[0])\n",
    "            pads = np.zeros((n_pads, x.shape[1]))\n",
    "            pads[:, -1] = 1\n",
    "            return np.concatenate((x, pads), axis=0)\n",
    "\n",
    "        if not hasattr(self, \"max_label_seq_len\"):\n",
    "            self.max_label_seq_len = max(targets, key=len).shape[0]\n",
    "        max_len = self.max_label_seq_len\n",
    "        n_actions = targets[0].shape[1]\n",
    "        padded = map(lambda x: pad(x), targets)\n",
    "        return np.array(list(padded))\n",
    "\n",
    "    def label_sequence(self, sqls, questions):\n",
    "        \"\"\"\n",
    "        iterate over list of sqls and questions\n",
    "        \"\"\"\n",
    "        seq = map(lambda sql, question: self._label_sequence(sql, question), sqls, questions)\n",
    "\n",
    "        targets = np.array(list(seq))\n",
    "        return self.pad_label_sequence(targets)\n",
    "\n",
    "    def _label_sequence(self, sql, question):\n",
    "        \"\"\"\n",
    "        1-0-1 iteration over a sql and the corresponding question\n",
    "        \"\"\"\n",
    "\n",
    "        def init_seq():\n",
    "            seq = np.zeros(self.n_agg +\n",
    "                           self.max_columns_per_table +\n",
    "                           self.max_columns_per_table +\n",
    "                           self.n_ops +\n",
    "                           self.max_words_per_question + 2)\n",
    "            return seq\n",
    "\n",
    "        seq = []\n",
    "        start = init_seq()\n",
    "        end = init_seq()\n",
    "\n",
    "        agg = init_seq()\n",
    "        sel = init_seq()\n",
    "\n",
    "        start[self.start_index] = 1\n",
    "        end[self.end_index] = 1\n",
    "        agg[self.agg_index] = self.ohe_agg([sql['agg']])\n",
    "        sel[self.sel_index] = self.ohe_column([sql['sel']])\n",
    "\n",
    "        seq.extend([start, agg, sel])\n",
    "\n",
    "        for condcol, condops, condval in sql['conds']:\n",
    "            condcol_seq = init_seq()\n",
    "            condops_seq = init_seq()\n",
    "            condval_start_seq = init_seq()\n",
    "            condval_end_seq = init_seq()\n",
    "\n",
    "            condcol_seq[self.concol_index] = self.ohe_column([condcol])\n",
    "            condops_seq[self.conops_index] = self.ohe_ops([condops])\n",
    "            #             _, start_index, end_index = self.get_condition_seq([condval], [question])\n",
    "            _, condval_start_seq[self.condval_index], condval_end_seq[self.condval_index] = self.get_condition_seq(\n",
    "                [condval], [question])\n",
    "            seq.extend([condcol_seq, condops_seq, condval_start_seq, condval_end_seq])\n",
    "        #         return seq\n",
    "        seq.append(end)\n",
    "        return np.array(seq)\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1285484 word vectors.\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "datatransformer = DataTransformer(df_train['question'].values, df_train['header'].values, df_train['sql'].values, cond_ops, agg_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_label = datatransformer.reverse_label_sequence(train_target, questions=df_train['question'].values)\n",
    "# reverse_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sony_df = pd.read_csv('nl2sql/Sony_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = datatransformer.transform_questions(df_train['question'].values)\n",
    "train_columns_sequences = datatransformer.transform_columns(df_train['header'].values)\n",
    "train_target = datatransformer.label_sequence(df_train['sql'].values, df_train['question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['State/territory',\n",
       "  'Text/background colour',\n",
       "  'Format',\n",
       "  'Current slogan',\n",
       "  'Current series',\n",
       "  'Notes'],\n",
       " ['state territory',\n",
       "  'text background colour',\n",
       "  'format',\n",
       "  'current slogan',\n",
       "  'current series',\n",
       "  'notes',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[1, 'header'], datatransformer.tokenizer.sequences_to_texts(train_columns_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = datatransformer.transform_questions(df_test['question'].values)\n",
    "test_columns_sequences = datatransformer.transform_columns(df_test['header'].values)\n",
    "test_target = datatransformer.label_sequence(df_test['sql'].values, df_test['question'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# train_sequences, train_columns_sequences, train_target = pickle.load(open('data/train_data.pic', 'rb'))\n",
    "pickle.dump([train_sequences, train_columns_sequences, train_target], open('data/train_data.pic', 'wb'))\n",
    "# test_sequences, test_columns_sequences, test_target = pickle.load(open('data/test_data.pic', 'rb'))\n",
    "pickle.dump([test_sequences, test_columns_sequences, test_target], open('data/test_data.pic', 'wb'))\n",
    "# import pickle\n",
    "# datatransformer = pickle.load(open('data/datatransformerlemm.pic', 'rb'))\n",
    "pickle.dump(datatransformer, open('data/datatransformerlemm.pic', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_agg_ohe, test_column_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "class TrainingDataSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "      \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "# device = torch.device('cuda: 0')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_tensors = torch.tensor(datatransformer.embedding_matrix, device=device, dtype=torch.float) \n",
    "\n",
    "train_sequences_tensor = torch.tensor(train_sequences, device=device, dtype=torch.long, requires_grad=False)\n",
    "test_sequences_tensor = torch.tensor(test_sequences, device=device, dtype=torch.long, requires_grad=False)\n",
    "\n",
    "\n",
    "test_columns_sequences_tensor = torch.tensor(test_columns_sequences, device=device, dtype=torch.long, requires_grad=False)\n",
    "train_columns_sequences_tensor = torch.tensor(train_columns_sequences, device=device, dtype=torch.long, requires_grad=False)\n",
    "\n",
    "\n",
    "train_target_tensor = torch.tensor(train_target, device=device, dtype=torch.long, requires_grad=False)\n",
    "test_target_tensor = torch.tensor(test_target, device=device, dtype=torch.long, requires_grad=False)\n",
    "\n",
    "train_dataset = TrainingDataSet(list(zip(train_sequences_tensor, train_columns_sequences_tensor)), train_target)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "test_dataset = TrainingDataSet(list(zip(test_sequences_tensor, test_columns_sequences_tensor)), test_target)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "# embedding_tensors.shape, embedding_matrix.shape                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15878, 26]),\n",
       " torch.Size([15878, 44, 5]),\n",
       " torch.Size([15878, 20, 127]),\n",
       " torch.Size([56355, 26]),\n",
       " torch.Size([56355, 20, 127]),\n",
       " torch.Size([56355, 44, 5]),\n",
       " (31009, 300))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_tensor.shape, test_columns_sequences_tensor.shape, test_target_tensor.shape, \\\n",
    "train_sequences_tensor.shape, train_target_tensor.shape,\\\n",
    "train_columns_sequences_tensor.shape, datatransformer.embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('numtagrd', 'party')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatransformer.tokenizer.index_word[621], datatransformer.tokenizer.index_word[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix,\n",
    "                 max_columns_per_table,\n",
    "                 max_words_per_question,\n",
    "                 n_lstm_cells=100,\n",
    "                 bidirectional=True,\n",
    "                 trainable_embedding=True, n_layers=1):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        vocab = embedding_matrix.shape[0]\n",
    "        feature_dim = embedding_matrix.shape[1]\n",
    "\n",
    "        self.word_embedding = nn.Embedding(vocab, feature_dim, _weight=embedding_matrix)\n",
    "\n",
    "        self.word_embedding.weight.require_grad = trainable_embedding\n",
    "\n",
    "        self.column_encoder = nn.LSTM(feature_dim,\n",
    "                                      n_lstm_cells,\n",
    "                                      num_layers=n_layers,\n",
    "                                      bidirectional=bidirectional)\n",
    "\n",
    "        self.question_encoder = nn.LSTM(feature_dim,\n",
    "                                        n_lstm_cells,\n",
    "                                        num_layers=n_layers,\n",
    "                                        bidirectional=bidirectional)\n",
    "\n",
    "        self.attended_question_encoder = nn.LSTM(feature_dim + max_columns_per_table,\n",
    "                                                 n_lstm_cells,\n",
    "                                                 num_layers=n_layers,\n",
    "                                                 bidirectional=bidirectional)\n",
    "\n",
    "        self.attended_column_encoder = nn.LSTM(feature_dim + max_words_per_question,\n",
    "                                               n_lstm_cells,\n",
    "                                               num_layers=n_layers,\n",
    "                                               bidirectional=bidirectional)\n",
    "\n",
    "        self.n_layers = n_layers * 2 if bidirectional else n_layers\n",
    "\n",
    "        self.n_lstm_cells = n_lstm_cells\n",
    "\n",
    "        self.max_columns_per_table = max_columns_per_table\n",
    "        self.max_words_per_question = max_words_per_question\n",
    "\n",
    "        self.attention_1 = nn.Linear(self.n_layers * self.n_lstm_cells, (self.n_layers * self.n_lstm_cells) // 2)\n",
    "\n",
    "        self.attention_2 = nn.Linear((self.n_layers * self.n_lstm_cells) // 2, 1)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h_0, c_0 = [torch.zeros((self.n_layers, batch_size, self.n_lstm_cells), require_grad=False)] * 2\n",
    "        return h_0, c_0\n",
    "\n",
    "    def self_attention(self, output):\n",
    "        #         output.shape() -> seq_len, batch_size, n_lstm_cells * n_layers\n",
    "        output = output.transpose(1, 0, 2)\n",
    "        atten_weights = self.attention_2(F.tanh(self.attention_1(output))).squeeze()\n",
    "        #         atten_weights.shape() -> batch_size, seq_len\n",
    "        atten_weights = F.softmax(atten_weights, dim=1)\n",
    "        #         atten_weights.shape() -> batch_size, seq_len\n",
    "        #         output.shape() -> batch_size, seq_len, n_lstm_cells * n_layers\n",
    "        attended_output = torch.bmm(output.transpose(0, 2, 1), atten_weights.unsqueeze(2))\n",
    "        #         attented_output.shape() -> batch_size, n_lstm_cells * n_layers\n",
    "        return attended_output\n",
    "\n",
    "    def alignment_attention(self, lstm_outputs, last_output):\n",
    "        #         lstm_outputs.shape -> (batch_size, seq_len, hidden_size * n_layers)\n",
    "        #         last_output.shape -> (batch_size, n_layers, hidden_size)\n",
    "        lstm_outputs = lstm_outputs.permute(2, 1, 0)[-self.n_lstm_cells:].permute(2, 1, 0)\n",
    "        #         lstm_outputs.shape -> (batch_size, seq_len, hidden_size)\n",
    "        similarity = torch.bmm(lstm_outputs, last_output.permute(1, 0, 2)[-1].unsqueeze(2))\n",
    "        #         similarity.shape -> (batch_size, seq_len, 1)\n",
    "\n",
    "        atten_weights = F.softmax(similarity.squeeze(2), dim=1)\n",
    "\n",
    "        attended = torch.bmm(atten_weights.unsqueeze(1), lstm_outputs).squeeze(2)\n",
    "        #         attended.shape -> (batch_size, hidden_size)\n",
    "\n",
    "        return attended\n",
    "\n",
    "    def encode_columns(self, columns):\n",
    "        batch_size, columns_per_table, words_per_column, embedding_dim = columns.shape\n",
    "        columns = columns.view(-1, words_per_column, embedding_dim).permute(1, 0, 2)\n",
    "        output, (ht, ct) = self.column_encoder(columns)\n",
    "        # ht.shape -> n_layers, batch_size * columns_per_table, n_lstm_cells\n",
    "        # output.shape -> words_per_column, batch_size * columns_per_table, n_dir * n_lstm_cells/hidden_size\n",
    "\n",
    "        encoded_columns = output[-1].view(batch_size, columns_per_table, -1)\n",
    "        # encoded_columns = ht.permute(1, 0, 2)[-1].view(batch_size, columns_per_table, -1)\n",
    "        # encoded_columns.shape -> (batch_size, columns_per_table, hidden_size\n",
    "        return encoded_columns\n",
    "\n",
    "    #     def encode_questions(self, questions):\n",
    "    #         output, (ht, ct) = self.question_encoder(questions)\n",
    "\n",
    "    #         encoded_questions = self.alignment_attention(output.permute(1, 0, 2), ht.permute(1, 0, 2))\n",
    "\n",
    "    def cross_attention(self, output_questions, output_columns):\n",
    "        #         output_questions.shape -> (batch_size, seq_len, hidden_size)\n",
    "        #         output_columns.shape -> (batch_size, columns_per_table, hidden_size)\n",
    "        cross_attended = torch.bmm(output_questions, output_columns.permute(0, 2, 1))\n",
    "        #         cross_attended.shape -> (batch_size, seq_len, columns_per_table)\n",
    "        question_seq, column_seq = cross_attended, cross_attended.permute(0, 2, 1)\n",
    "        return question_seq, column_seq\n",
    "\n",
    "    def forward(self, questions, columns):\n",
    "        questions = self.word_embedding(questions)\n",
    "        columns = self.word_embedding(columns)\n",
    "        questions_output, _ = self.question_encoder(questions.permute(1, 0, 2))\n",
    "        questions_output = questions_output.permute(1, 0, 2)\n",
    "        columns_output = self.encode_columns(columns)\n",
    "        cross_attended_questions, cross_attended_columns = self.cross_attention(questions_output, columns_output)\n",
    "\n",
    "        questions_cross_attended = torch.cat((questions_output, cross_attended_questions), dim=2)\n",
    "        columns_cross_attended = torch.cat((columns_output, cross_attended_columns), dim=2)\n",
    "\n",
    "        questions_output, _ = self.attended_question_encoder(questions_cross_attended.permute(1, 0, 2))\n",
    "\n",
    "        columns_output, _ = self.attended_column_encoder(columns_cross_attended.permute(1, 0, 2))\n",
    "\n",
    "        # lstm_output.shape -> seq_len, batch_size, n_dir * hidden_size\n",
    "        # lstm_ht.shape -> n_layer * n_dir, batch_size, hidden_size\n",
    "\n",
    "        # transposing to batch_first.\n",
    "        questions_encoded = questions_output[-1]\n",
    "\n",
    "        return questions_output.permute(1, 0, 2), columns_output.permute(1, 0, 2), questions_encoded\n",
    "\n",
    "\n",
    "#         return questions_ht.permute(1, 0, 2), columns_ht.permute(1, 0, 2), columns_seq\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_lstm_cells,\n",
    "                 repr_dim,\n",
    "                 n_layers,\n",
    "                 op_seq_len,\n",
    "                 action_embedding_dim,\n",
    "                 bidirectional,\n",
    "                 agg_ops,\n",
    "                 cond_ops,\n",
    "                 states,\n",
    "                 use_self_attention=False):\n",
    "        \"\"\"\n",
    "        repr_dim -> hidden_dim of the encoded questions/columns\n",
    "        op_seq_len -> max_length of the generated query\n",
    "\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        #         self.action_embedding = nn.Embedding(len(actions), embedding_size)\n",
    "\n",
    "        self.n_states = len(states) + len(cond_ops) + len(agg_ops) - 2\n",
    "\n",
    "        self.action_embedding = nn.Embedding(self.n_states, action_embedding_dim)\n",
    "\n",
    "        feature_dim = repr_dim + action_embedding_dim\n",
    "        #         feature_dim += embedding_size\n",
    "        self.decoder_lstm = nn.LSTM(feature_dim,\n",
    "                                    n_lstm_cells,\n",
    "                                    num_layers=n_layers,\n",
    "                                    bidirectional=bidirectional)\n",
    "\n",
    "        self.bilinear = nn.Bilinear(n_lstm_cells, repr_dim + action_embedding_dim, 1)\n",
    "\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        self.n_lstm_cells = n_lstm_cells\n",
    "        self.n_layers = n_layers * 2 if bidirectional else n_layers\n",
    "\n",
    "        self.agg_ops = agg_ops\n",
    "\n",
    "        self.cond_ops = cond_ops\n",
    "\n",
    "        self.start_idx = torch.arange(0, 1, device=device, dtype=torch.long)\n",
    "        self.agg_idx = torch.arange(1, len(agg_ops) + 1, device=device, dtype=torch.long)\n",
    "        self.selcol_idx = torch.arange(len(agg_ops) + 1, len(agg_ops) + 2, device=device, dtype=torch.long)\n",
    "        self.condcol_idx = torch.arange(len(agg_ops) + 2, len(agg_ops) + 3, device=device, dtype=torch.long)\n",
    "        self.condop_idx = torch.arange(len(agg_ops) + 3, len(agg_ops) + 3 + len(cond_ops), device=device,\n",
    "                                       dtype=torch.long)\n",
    "        self.condval_idx = torch.arange(len(agg_ops) + 3 + len(cond_ops), len(agg_ops) + 3 + len(cond_ops) + 1,\n",
    "                                        device=device, dtype=torch.long)\n",
    "        self.end_idx = torch.arange(len(agg_ops) + 3 + len(cond_ops) + 1, len(agg_ops) + 3 + len(cond_ops) + 2,\n",
    "                                    device=device, dtype=torch.long)\n",
    "\n",
    "        self.embedding_size = action_embedding_dim\n",
    "        self.use_attention = use_self_attention\n",
    "        self.op_seq_len = op_seq_len\n",
    "\n",
    "    def generate_action_matrix(self, questions_encoded, columns_output, questions_output):\n",
    "        # cols_repr_vector.shape -> batch_size, max_cols_per_tables, encoding_length\n",
    "        # questions_repr_vector.shape -> batch_size, encoding_length\n",
    "        # questions_output -> batch_size, max_words_per_question, endoding_length\n",
    "\n",
    "        #         agg_idx = self.action_indices['agg']\n",
    "\n",
    "        #         selcol_idx = self.action_indices['selcol']\n",
    "\n",
    "        #         condcol_idx = self.action_indices['condcol']\n",
    "        #         condop_idx = self.action_indices['condop']\n",
    "        #         condval_idx = self.action_indices['condval']\n",
    "\n",
    "        #         end_idx = self.actions['end']\n",
    "\n",
    "        seq_len = questions_output.shape[-2]\n",
    "        col_len = columns_output.shape[-2]\n",
    "        hidden_size = questions_encoded.shape[-1]\n",
    "        batch_size = questions_encoded.shape[0]\n",
    "\n",
    "        # padding_zeros shape -> 1, hiddent_size of question/column encoding\n",
    "        padding_zeros = torch.zeros(1, hidden_size, device=device, requires_grad=False)\n",
    "\n",
    "        # start_matrix shape -> 1, hidden_size of action_embedding\n",
    "        start_vector = torch.cat((self.action_embedding(self.start_idx), padding_zeros), dim=1).repeat(batch_size, 1, 1)\n",
    "\n",
    "        # agg_matrix shape -> n_ops, hiddden_size\n",
    "        agg_vector = torch.cat((self.action_embedding(self.agg_idx),\n",
    "                                padding_zeros.repeat(self.agg_idx.shape[0], 1)), dim=1).repeat(batch_size, 1, 1)\n",
    "\n",
    "        #\n",
    "        selcol_vector = torch.cat((self.action_embedding(self.selcol_idx).repeat(batch_size, col_len, 1),\n",
    "                                   columns_output), dim=2)\n",
    "\n",
    "        concol_vector = torch.cat((self.action_embedding(self.condcol_idx).repeat(batch_size, col_len, 1),\n",
    "                                   columns_output), dim=2)\n",
    "\n",
    "        condops_vector = torch.cat((self.action_embedding(self.condop_idx),\n",
    "                                    padding_zeros.repeat(self.condop_idx.shape[0], 1)), dim=1).repeat(batch_size, 1, 1)\n",
    "\n",
    "        condval_vector = torch.cat((self.action_embedding(self.condval_idx).repeat(batch_size, seq_len, 1),\n",
    "                                    questions_output), dim=2)\n",
    "\n",
    "        end_vector = torch.cat((self.action_embedding(self.end_idx), padding_zeros),\n",
    "                               dim=1).repeat(batch_size, 1, 1)\n",
    "\n",
    "        all_actions_matrix = torch.cat([start_vector,\n",
    "                                        agg_vector,\n",
    "                                        selcol_vector,\n",
    "                                        concol_vector,\n",
    "                                        condops_vector,\n",
    "                                        condval_vector,\n",
    "                                        end_vector], dim=1)\n",
    "        # that was tough\n",
    "\n",
    "        return all_actions_matrix\n",
    "\n",
    "    #     def get_action_vector(self, output_seq, n_words_per_question, n_columns_per_table):\n",
    "    #         index = output_seq.argmax()\n",
    "\n",
    "    # #         {'start_idx' : np.arange(0, 1),\n",
    "    # #         'agg_idx':  np.arange(1, )}\n",
    "\n",
    "    #         # for start and agg index\n",
    "    #         if index < 1 + len(self.agg_ops):\n",
    "    #             return self.action_embedding.weight[index]\n",
    "\n",
    "    #         # selcol\n",
    "    #         elif index < 1 + len(self.agg_ops) + n_columns_per_table:\n",
    "    #             return self.action_embedding.weight[1 + len(self.agg_ops)]\n",
    "\n",
    "    #         # condcols\n",
    "    #         elif index <  1 + len(self.agg_ops) + 2 * n_columns_per_table:\n",
    "    #             index = 1 + len(self.agg_ops) + 1\n",
    "    #             return self.action_embedding.weight[index]\n",
    "\n",
    "    #         # condops\n",
    "    #         elif index <  1 + len(self.agg_ops) + 2 * n_columns_per_table + len(self.cond_ops):\n",
    "    #             index = index - (1 + len(self.agg_ops) + 2 * n_columns_per_table)  + (1 + len(self.agg_ops) + 2)\n",
    "    #             return self.action_embedding.weight[index]\n",
    "\n",
    "    #         # condval\n",
    "    #         elif index <  1 + len(self.agg_ops) + 2 * n_columns_per_table + len(self.cond_ops) + n_words_per_question:\n",
    "    #             index = 1 + len(self.agg_ops) + 2 + len(self.cond_ops)\n",
    "    #             return self.action_embedding.weight[index]\n",
    "\n",
    "    #         # end\n",
    "    #         elif index <  1 + len(self.agg_ops) + 2 * n_columns_per_table + len(self.cond_ops) + n_words_per_question + 1:\n",
    "    #             index =  1 + len(self.agg_ops) + 2 + len(self.cond_ops) + 1\n",
    "    #             return self.action_embedding.weight[index]\n",
    "\n",
    "    def global_attention(questions_output, target):\n",
    "        pass\n",
    "\n",
    "    def get_action_vector_from_output(self, output_seq, action_matrix):\n",
    "        \"\"\"\n",
    "        output_seq.shape -> batch_size, n_actions\n",
    "        action_matrix.shape -> batch_size, n_actions, hidden_size\n",
    "        \"\"\"\n",
    "        top_index = torch.argmax(output_seq, dim=1).detach()\n",
    "        actions = torch.cat([action_matrix[n_batch_index, action_index, :self.embedding_size].unsqueeze(0).detach()\n",
    "                             for n_batch_index, action_index in enumerate(top_index)], dim=0)\n",
    "\n",
    "        #         action_matrix.shape -> batch_size, self.embedding_size/action_embedding_dim\n",
    "        return actions\n",
    "\n",
    "    def forward_step(self, previous_action_vector, questions_encoded, previous_hidden, output_actions_matrix):\n",
    "        \"\"\"\n",
    "        takes the previous_state batch and predicts the next token\n",
    "        \"\"\"\n",
    "        # previous_action_vector.shape -> batch_size, action_embedding_dim\n",
    "        # questions_encoded.shape -> batch_size, hidden_dim\n",
    "        # output_actions_matrix.shape -> batch_size, n_possible_actions, hidden_size\n",
    "        #         question_encoded = self.question_encoder()\n",
    "\n",
    "        n_actions_outputs = output_actions_matrix.shape[-2]\n",
    "\n",
    "        decoder_ip = torch.cat((previous_action_vector, questions_encoded), dim=1)\n",
    "\n",
    "        decoder_ip = decoder_ip.unsqueeze(1).permute(1, 0, 2)\n",
    "        _, hidden_states = self.decoder_lstm(decoder_ip, previous_hidden)\n",
    "        last_output = hidden_states[0][-1]\n",
    "        # last_output.shape -> batch_size, hidden_size/decoder_n_lstm_cells\n",
    "        last_output = last_output.unsqueeze(1).repeat(1, n_actions_outputs, 1)\n",
    "        # last_ouput.shape -> batch_size, n_actions_outputs, hidden_size\n",
    "\n",
    "        bilinear_output = self.bilinear(last_output, output_actions_matrix)\n",
    "        # bilinear_output.shape -> batch_size, n_actions_ouputs, 1\n",
    "        bilinear_output = bilinear_output.squeeze(2)\n",
    "\n",
    "        return bilinear_output, hidden_states\n",
    "\n",
    "    def generate_hidden(self, batch_size):\n",
    "        n_layers = self.n_layers\n",
    "        h_0 = torch.zeros(n_layers, batch_size, self.n_lstm_cells, requires_grad=False, device=device)\n",
    "        c_0 = torch.zeros(n_layers, batch_size, self.n_lstm_cells, requires_grad=False, device=device)\n",
    "        return h_0, c_0\n",
    "\n",
    "    def forward(self, questions_encoded, questions_output, columns_output, teacher_forcing_ratio=0,\n",
    "                target_output_seq=None):\n",
    "        \"\"\"\n",
    "        questions_encoded.shape -> batch_size, hidden_size | question representation\n",
    "        columns_output_vector.shape -> batch_size, max_columns_per_table, hidden_size | column representation\n",
    "        questions_output.shape -> batch_size, max_word_per_table, hidden_size | question representation at word level, used for attention\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = questions_encoded.shape[0]\n",
    "        # Prediction for start not required, start from index = 1\n",
    "        previous_hidden = self.generate_hidden(batch_size)\n",
    "\n",
    "        # start action\n",
    "        previous_action = self.action_embedding.weight[0].repeat(batch_size, 1)\n",
    "        action_matrix = self.generate_action_matrix(questions_encoded, columns_output, questions_output)\n",
    "        # action_matrix.shape -> batch_size, n_actions, action_embedding_size(+repr_dim)\n",
    "        start_seq = torch.zeros((batch_size, 1, action_matrix.shape[-2]), device=device)\n",
    "        start_seq[:, 0] = 1\n",
    "\n",
    "        output_seq_list = [start_seq]\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if not use_teacher_forcing:\n",
    "            for index in range(1, self.op_seq_len):\n",
    "                output_seq, previous_hidden = self.forward_step(previous_action, questions_encoded, previous_hidden,\n",
    "                                                                action_matrix)\n",
    "                previous_action = self.get_action_vector_from_output(output_seq, action_matrix)\n",
    "                output_seq_list.append(output_seq.unsqueeze(1))\n",
    "        else:\n",
    "            for index in range(1, self.op_seq_len):\n",
    "                output_seq, previous_hidden = self.forward_step(previous_action, questions_encoded, previous_hidden,\n",
    "                                                                action_matrix)\n",
    "                #                 output_seq.shape -> batch_size, op_seq_len\n",
    "                previous_action = target_output_seq[:, index - 1, :]\n",
    "                output_seq_list.append(output_seq.unsqueeze(1))\n",
    "\n",
    "        out_seqs = torch.cat(output_seq_list, dim=1)\n",
    "        # out_seqs.shape -> batch_size, op_seq_len, n_actions\n",
    "\n",
    "        return out_seqs\n",
    "\n",
    "\n",
    "class NL2SQL(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, ):\n",
    "        super(NL2SQL, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.encoder = encoder\n",
    "#         self.flatten_parameters()\n",
    "\n",
    "    @classmethod\n",
    "    def initialise_encoder_decoder_network(cls, encoder_word_embedding_matrix,\n",
    "                                           encoder_max_columns_per_table,\n",
    "                                           encoder_max_words_per_question,\n",
    "                                           encoder_n_lstm_cells,\n",
    "                                           encoder_bidirectional,\n",
    "                                           encoder_trainable_embedding,\n",
    "                                           encoder_n_layers,\n",
    "                                           decoder_n_lstm_cells,\n",
    "                                           decoder_n_layers,\n",
    "                                           decoder_op_seq_len,\n",
    "                                           decoder_action_embedding_dim,\n",
    "                                           decoder_bidirectional,\n",
    "                                           decoder_agg_ops,\n",
    "                                           decoder_cond_ops,\n",
    "                                           decoder_states, ):\n",
    "        encoder = Encoder(embedding_matrix=encoder_word_embedding_matrix,\n",
    "                          max_columns_per_table=encoder_max_columns_per_table,\n",
    "                          max_words_per_question=encoder_max_words_per_question,\n",
    "                          n_lstm_cells=encoder_n_lstm_cells,\n",
    "                          bidirectional=encoder_bidirectional,\n",
    "                          trainable_embedding=encoder_trainable_embedding,\n",
    "                          n_layers=encoder_n_layers)\n",
    "        decoder = Decoder(n_lstm_cells=decoder_n_lstm_cells,\n",
    "                          repr_dim=encoder_n_lstm_cells * 2 if encoder_bidirectional else 1,\n",
    "                          n_layers=decoder_n_layers,\n",
    "                          op_seq_len=decoder_op_seq_len,\n",
    "                          action_embedding_dim=decoder_action_embedding_dim,\n",
    "                          bidirectional=decoder_bidirectional,\n",
    "                          agg_ops=decoder_agg_ops,\n",
    "                          cond_ops=decoder_cond_ops,\n",
    "                          states=decoder_states,\n",
    "                          use_self_attention=False)\n",
    "        \n",
    "        return cls(encoder, decoder)\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        self.encoder.flatten_parameters()\n",
    "        self.decoder.rnn.flatten_parameters()\n",
    "\n",
    "    def forward(self, questions, columns, teacher_forcing_ratio=0., target_output_seq=None):\n",
    "        questions_output, columns_output, questions_encoded = self.encoder(questions, columns)\n",
    "        out_seqs = self.decoder(questions_encoded, questions_output,\n",
    "                                columns_output, teacher_forcing_ratio, target_output_seq)\n",
    "        return out_seqs\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main___\":\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NL2SQL.initialise_encoder_decoder_network(encoder_word_embedding_matrix=embedding_tensors,\n",
    "                                                  encoder_max_columns_per_table=train_columns_sequences.shape[-2],\n",
    "                                                  encoder_max_words_per_question=train_sequences.shape[-1],\n",
    "                                                  encoder_n_lstm_cells=150,\n",
    "                                                  encoder_bidirectional=True,\n",
    "                                                  encoder_trainable_embedding=False,\n",
    "                                                  encoder_n_layers=1,\n",
    "                                                  decoder_n_lstm_cells=150,\n",
    "                                                  decoder_n_layers=1,\n",
    "                                                  decoder_op_seq_len=train_target.shape[-2],\n",
    "                                                  decoder_action_embedding_dim=15,\n",
    "                                                  decoder_bidirectional=True,\n",
    "                                                  decoder_agg_ops=datatransformer.agg,\n",
    "                                                  decoder_cond_ops=datatransformer.ops,\n",
    "                                                  decoder_states=datatransformer.states_index)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=torch.tensor(agg_weights, device=device, requires_grad=False, dtype=torch.float))\n",
    "#     weight=torch.tensor([1, 2, 2, 2, 2, 2], dtype=torch.float, device=device,\n",
    "#                                                         requires_grad=False))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.6731091858311133, batch: 880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    for batch_no, (X, y) in enumerate(train_dataloader):\n",
    "        #         print(y.shape)\n",
    "        batch_size, op_seq_len, n_actions = y.shape\n",
    "        y = y.view(-1, n_actions)\n",
    "        y_pred = model(*X)\n",
    "        # print(y_pred.shape)\n",
    "        y_pred = y_pred.view(-1, n_actions)\n",
    "\n",
    "        _, y_true_label = torch.max(y, 1)\n",
    "        loss = loss_function(y_pred, y_true_label.cuda().long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        # print('\\r', \"Loss: {}, batch: {}\".format(loss_value / (batch_no if batch_no > 0 else 1), batch_no), end=\"\")\n",
    "        print('\\r', \"Loss: {}, batch: {}\".format(loss_value / (batch_no if batch_no > 0 else 1), batch_no), end=\"\")\n",
    "    #         break\n",
    "    #     break\n",
    "\n",
    "    #     print('fc2:',  sel_nn.*fc2.weight)\n",
    "    torch.save(model, 'data/training/NL2SQLe:{epoch}.pt'.format(epoch=i))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        train_pred = []\n",
    "        train_true = []\n",
    "        train_pred_pd = []  # , torch.tensor([], dtype=torch.float)\n",
    "        train_true_pd = []  # , torch.tensor([], dtype=torch.float)\n",
    "\n",
    "        for X, y in train_dataloader:\n",
    "            batch_size, op_seq_len, n_actions = y.shape\n",
    "            y = y.view(-1, n_actions)\n",
    "            y_pred_train = model(*X)\n",
    "            y_pred_train = y_pred_train.view(-1, n_actions)\n",
    "\n",
    "            _, y_pred_train_label = torch.max(y_pred_train, 1)\n",
    "            _, y_true_train_label = torch.max(y, 1)\n",
    "\n",
    "            #             train_pred_pd = torch.cat((train_pred_pd, y_pred_train.cpu()))\n",
    "            #             train_true_pd = torch.cat((train_true_pd, y.cpu()))\n",
    "            train_pred_pd += y_pred_train.tolist()\n",
    "            train_true_pd += y.tolist()\n",
    "\n",
    "            train_pred += y_pred_train_label.tolist()\n",
    "            train_true += y_true_train_label.tolist()\n",
    "\n",
    "        test_pred = []\n",
    "        test_true = []\n",
    "        #         test_pred_pd = torch.tensor([], dtype=torch.float)\n",
    "        #         test_true_pd = torch.tensor([], dtype=torch.float)\n",
    "        test_pred_pd = []\n",
    "        test_true_pd = []\n",
    "        for X, y in test_dataloader:\n",
    "            batch_size, op_seq_len, n_actions = y.shape\n",
    "            y = y.view(-1, n_actions)\n",
    "            y_pred_test = model(*X)\n",
    "            y_pred_test = y_pred_test.view(-1, n_actions)\n",
    "\n",
    "            _, y_pred_test_label = torch.max(y_pred_test, 1)\n",
    "            _, y_true_test_label = torch.max(y, 1)\n",
    "\n",
    "            #             test_pred_pd = torch.cat((test_pred_pd, y_pred_test.cpu()))\n",
    "            #             test_true_pd = torch.cat((test_true_pd, y.cpu()))\n",
    "\n",
    "            test_pred_pd += y_pred_test.tolist()\n",
    "            test_true_pd += y.tolist()\n",
    "\n",
    "            test_pred += y_pred_test_label.tolist()\n",
    "            test_true += y_true_test_label.tolist()\n",
    "\n",
    "        print('\\n')\n",
    "\n",
    "        train_pred_pd = torch.tensor(train_pred_pd, device=device)\n",
    "        test_pred_pd = torch.tensor(test_pred_pd, device=device)\n",
    "\n",
    "        train_true_pd = torch.tensor(train_true_pd, device=device)\n",
    "        test_true_pd = torch.tensor(test_true_pd, device=device)\n",
    "\n",
    "        _, train_true_label = torch.max(train_true_pd, 1)\n",
    "        _, test_true_label = torch.max(test_true_pd, 1)\n",
    "\n",
    "        train_true_label = train_true_label.long()\n",
    "        test_true_label = test_true_label.long()\n",
    "\n",
    "        performance = {'epoch': i,\n",
    "                       'train_loss': loss_function(train_pred_pd.cuda(), train_true_label.cuda()).item(),\n",
    "                       'test_loss': loss_function(test_pred_pd.cuda(), test_true_label.cuda()).item(),\n",
    "                       'train_accuracy': accuracy_score(train_true, train_pred),\n",
    "                       'test_accuracy': accuracy_score(test_true, test_pred),\n",
    "                       'train_f1': f1_score(train_true, train_pred,\n",
    "                                            average='weighted'),\n",
    "                       'test_f1': f1_score(test_true, test_pred,\n",
    "                                           average='weighted')}\n",
    "\n",
    "        pprint.pprint(performance, indent=4)\n",
    "        pprint.pprint(performance, open('data/trainAttention.log', 'a+'), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_nn = torch.load('nl2sql/trained/AggSelPredictorEpoch8.pt')\n",
    "# sel_nn = torch.load(\"nl2sql/trained/SelAggPredictorWOWeightsEpoch5.pt\")\n",
    "# sel_nn = torch.load(\"data/training/SelTrainableEmb7.pt\")\n",
    "sel_nn = torch.load('data/training/SelAggTrainableEmb2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type SelectPredictor. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(sel_nn, 'nl2sql/trained/AggSelPredictor2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6658751528846647"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.cosine(datatransformer.embedding_matrix[35], datatransformer.embedding_matrix[135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatransformer.transform_questions(['what is the longest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatransformer.tokenizer.word_index['game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "from nl2sql.nl2sql.predictor import Predictor\n",
    "def sub_cols(xs):\n",
    "    xs = list(map(lambda x: re.sub('ACCT', 'account', x, flags=re.IGNORECASE), xs))\n",
    "    return xs\n",
    "data_ = list(zip(sony_df['question'].values, sony_df.apply(lambda x: sub_cols(eval(x['header']))[x['sel_col']], axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sony():\n",
    "\n",
    "    def format_sql(sels, aggs):\n",
    "        sql = \"SELECT {agg}({col}) FROM t1\"\n",
    "        return [sql.format(agg=agg, col=sel) for agg, sel in zip(aggs, sels)]\n",
    "    \n",
    "    \n",
    "    def sub_find(x):\n",
    "        \n",
    "#         x = re.sub('find', 'what is', x, flags=re.IGNORECASE)\n",
    "#         x = re.sub('account', 'account', x, flags=re.IGNORECASE)\n",
    "#         x = re.sub('id', 'id', x, flags=re.IGNORECASE)\n",
    "        x = re.sub('franchisee', 'franchise', x, flags=re.IGNORECASE)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "    predictor = Predictor(sel_nn, datatransformer)\n",
    "    preds = predictor.predict_selcol(sony_df.question.apply(sub_find).values, \n",
    "                        sony_df.header.apply(lambda x: sub_cols(eval(x))).values)\n",
    "    return list(zip(format_sql(*preds), data_))\n",
    "# pp.pprint(print_sony())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], dtype=torch.int8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  torch.tensor([[2,3], [4,1]])\n",
    "# a.type(torch.float16).cpu().numpy().tolist()\n",
    "_, v = torch.max(a, 1)\n",
    "v.type(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_single(y_true, y_pred):\n",
    "    n_classes = set(y_true)\n",
    "    \n",
    "    y_pred = set(y_pred)\n",
    "    cross_size = len(y_true & y_pred)\n",
    "    if cross_size == 0: return 0.\n",
    "    p = 1. * cross_size / len(y_pred)\n",
    "    r = 1. * cross_size / len(y_true)\n",
    "    return 2 * p * r / (p + r)\n",
    "    \n",
    "def f1_score(y_true, y_pred):\n",
    "    return np.mean([f1_score_single(x, y) for x, y in zip(y_true, y_pred)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-16914cb4d14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnl2sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl2sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequencePredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/training/NL2SQLe:0.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from nl2sql.nl2sql.predictor import SequencePredictor\n",
    "import torch\n",
    "model = torch.load(\"data/training/NL2SQLe:0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sel_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-14d07f851042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequencePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformat_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT {agg}({col}) FROM t1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sel_nn' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = SequencePredictor(sel_nn, datatransformer)\n",
    "\n",
    "def format_sql(sels, aggs):\n",
    "    sql = \"SELECT {agg}({col}) FROM t1\"\n",
    "    return [sql.format(agg=agg, col=sel) for agg, sel in zip(aggs, sels)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:144: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/project/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/project/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:126: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SELECT MAX(salary) FROM t1',\n",
       " 'SELECT COUNT(salary) FROM t1',\n",
       " 'SELECT (fighter) FROM t1',\n",
       " 'SELECT COUNT_DISTINCT(currency) FROM t1',\n",
       " 'SELECT AVG(salary) FROM t1',\n",
       " 'SELECT MIN(no) FROM t1',\n",
       " 'SELECT MAX(relative atomic mass) FROM t1']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predictor.predict_selcol(['Who is the highest paid employee ?',\n",
    "                                  'How many employees are paid greater than 1000 ?', \n",
    "                          'who are the fighter with no losses in wwe ?',\n",
    "                          'how many distinct number of currency are used in Australia ? ',\n",
    "                          'what is the average pay?',\n",
    "                          'what is the lowest ctc ?',\n",
    "                         'what is the highest electrons?'], \n",
    "                    [['ID', 'salary', 'age', 'sex', 'designation', 'date of joining', 'address'],\n",
    "                     ['ID', 'salary', 'age', 'sex', 'designation', 'date of joining', 'address'],\n",
    "                     ['fighter', 'weight', 'wins', 'losses', 'origin'],\n",
    "                    ['currency', 'US dollar value', 'country'],\n",
    "                    ['no', 'salary', 'age', 'sex', 'designation', 'date of joining', 'address'],\n",
    "                    ['no', 'salary', 'age', 'sex', 'designation', 'date of joining', 'address'],\n",
    "                    ['id', 'element', 'relative atomic mass', 'atomic number']])\n",
    "format_sql(*preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_true, y_pred = pickle.load(open('true_pred_ex.pic', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sel_nn.state_dict(), \"data/AggSelPredictorState.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm, test_cm = pickle.load(open('data/training/ConfusionMatrix|e:8.pic', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': {'total_fn': 2883,\n",
       "  'total_tn': 298185,\n",
       "  'total_fp': 195,\n",
       "  'total_tp': 16297,\n",
       "  'total_obs': 19180,\n",
       "  'precision': 0.9881760853747271,\n",
       "  'recall': 0.8496871741397288,\n",
       "  'f1': 0.913713837183225,\n",
       "  'accuracy': 0.990307343494143},\n",
       " 'aggop': {'total_fn': 2285,\n",
       "  'total_tn': 1570223,\n",
       "  'total_fp': 2305,\n",
       "  'total_tp': 12987,\n",
       "  'total_obs': 15272,\n",
       "  'precision': 0.8762204335089299,\n",
       "  'recall': 0.8503797799895233,\n",
       "  'f1': 0.8494341297974645,\n",
       "  'accuracy': 0.996109589854239},\n",
       " 'selcol': {'total_fn': 1455,\n",
       "  'total_tn': 13955308,\n",
       "  'total_fp': 1454,\n",
       "  'total_tp': 14423,\n",
       "  'total_obs': 15878,\n",
       "  'precision': 0.9091137377487541,\n",
       "  'recall': 0.9083637737750346,\n",
       "  'f1': 0.9084083239794395,\n",
       "  'accuracy': 0.9987050949771767},\n",
       " 'condcols': {'total_fn': 4999,\n",
       "  'total_tn': 13946116,\n",
       "  'total_fp': 4678,\n",
       "  'total_tp': 16847,\n",
       "  'total_obs': 21846,\n",
       "  'precision': 0.7827906157049883,\n",
       "  'recall': 0.7711709237388996,\n",
       "  'f1': 0.7768072995080982,\n",
       "  'accuracy': 0.9953534441187939},\n",
       " 'condops': {'total_fn': 1872,\n",
       "  'total_tn': 1246645,\n",
       "  'total_fp': 1749,\n",
       "  'total_tp': 19974,\n",
       "  'total_obs': 21846,\n",
       "  'precision': 0.9198872626076665,\n",
       "  'recall': 0.9143092556989838,\n",
       "  'f1': 0.9168951652807937,\n",
       "  'accuracy': 0.9942292850270229},\n",
       " 'condval': {'total_fn': 4666,\n",
       "  'total_tn': 8224603,\n",
       "  'total_fp': 5715,\n",
       "  'total_tp': 21576,\n",
       "  'total_obs': 26242,\n",
       "  'precision': 0.7901542818049639,\n",
       "  'recall': 0.8221934303787821,\n",
       "  'f1': 0.8054923307517583,\n",
       "  'accuracy': 0.9965373241371678},\n",
       " 'end': {'total_fn': 1392,\n",
       "  'total_tn': 301212,\n",
       "  'total_fp': 2200,\n",
       "  'total_tp': 12756,\n",
       "  'total_obs': 14148,\n",
       "  'precision': 0.852901845413212,\n",
       "  'recall': 0.9016115351993215,\n",
       "  'f1': 0.876580538757559,\n",
       "  'accuracy': 0.9886887517319561}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['test_aggop', 'test_condcols', 'test_condops', 'test_condval',\n",
       "       'test_end', 'test_selcol', 'test_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.index.map(lambda x: 'test_'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/project/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/project/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'pandas.core.indexes.base.Index'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-3d17d204bc18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'test_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    284\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'pandas.core.indexes.base.Index'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "report = get_slotwise_report(test_cm, 26, 44, 6, 4)\n",
    "a= pd.DataFrame.from_dict(report, orient='index')\n",
    "a = \n",
    "b =  pd.DataFrame.from_dict(report, orient='index')\n",
    "pd.concat([a.index.map(lambda x: 'test_'+x), b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_cm).to_csv('data/cm_test.csv')\n",
    "pd.DataFrame(train_cm).to_csv('data/cm_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=', '>', '<', 'OP']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query.cond_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp / float(tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_metrics_cm_for_one_index(cm, index):\n",
    "    \n",
    "    n_samples = cm.ravel().sum()\n",
    "    total_obs = cm[index].sum()\n",
    "    tp = cm[index, index]\n",
    "    fp = cm[:, index].sum() - cm[index, index]\n",
    "    fn = cm[index].sum() - cm[index, index]\n",
    "    tn = n_samples - tp - fp - fn\n",
    "    \n",
    "    recall = tp / float(tp + fn)\n",
    "    precision = tp / float(tp + fp)\n",
    "    f1 = (2 * recall * precision) / (recall + precision)\n",
    "    accuracy = (tp + tn) / n_samples\n",
    "    \n",
    "    if not total_obs == 0:\n",
    "        recall = recall if not np.isnan(recall) else 0\n",
    "        f1 = f1 if not np.isnan(f1) else 0\n",
    "        precision = precision if not np.isnan(precision) else 0\n",
    "    else:\n",
    "        recall, f1, precision = 0, 0, 0\n",
    "        \n",
    "    return tp, tn, fp, fn, recall, precision, f1, accuracy, total_obs\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "def get_indexwise_metrics(cm):\n",
    "    report = {}\n",
    "    for index in range(0, len(cm)):\n",
    "        tp, tn, fp, fn, recall, precision, f1, accuracy, total_obs = get_metrics_cm_for_one_index(cm, index)\n",
    "        report[index] = {'tp': tp,\n",
    "                         'tn': tn,\n",
    "                         'fp': fp,\n",
    "                         'fn': fn,\n",
    "                         'total_obs': total_obs,\n",
    "                         'recall':recall,\n",
    "                         'precision':precision,\n",
    "                         'f1':f1,\n",
    "                         'accuracy':accuracy}\n",
    "    return report\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "def get_metrics_cm_for_one_slot(metrics_df, start_index, end_index):\n",
    "\n",
    "    metrics_slot_df = metrics_df.iloc[start_index:end_index]\n",
    "    slot_report = dict()\n",
    "    slot_report['total_fn'] = metrics_slot_df['fn'].sum()\n",
    "    slot_report['total_tn'] = metrics_slot_df['tn'].sum()\n",
    "    slot_report['total_fp'] = metrics_slot_df['fp'].sum()\n",
    "    slot_report['total_tp'] = metrics_slot_df['tp'].sum()\n",
    "    slot_report['total_obs'] = metrics_slot_df['total_obs'].sum()\n",
    "    slot_report['precision'] = ((metrics_slot_df['precision'] * metrics_slot_df['total_obs'])).sum()/ slot_report['total_obs']\n",
    "    slot_report['recall'] = ((metrics_slot_df['recall'] * metrics_slot_df['total_obs'])).sum()/ slot_report['total_obs']\n",
    "    slot_report['f1'] = ((metrics_slot_df['f1'] * metrics_slot_df['total_obs'])).sum()/ slot_report['total_obs']\n",
    "    slot_report['accuracy'] = ((metrics_slot_df['accuracy'] * metrics_slot_df['total_obs'])).sum()/ slot_report['total_obs']\n",
    "\n",
    "    return slot_report\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "def get_slotwise_report(cm, n_words_per_question,\n",
    "                        n_columns_per_table, n_agg_ops,\n",
    "                        n_cond_ops):\n",
    "    \n",
    "    indexwise_report = get_indexwise_metrics(cm)\n",
    "    metrics_df = pd.DataFrame.from_dict(indexwise_report, orient='index')\n",
    "    slotwise_report = {}\n",
    "    \n",
    "    # start\n",
    "    slotwise_report['start'] = get_metrics_cm_for_one_slot(metrics_df, 0, 1)\n",
    "    \n",
    "    # aggops\n",
    "    slotwise_report['aggop'] = get_metrics_cm_for_one_slot(metrics_df, 1, n_agg_ops)\n",
    "\n",
    "    # selcol\n",
    "    slotwise_report['selcol'] = get_metrics_cm_for_one_slot(metrics_df, 1 + n_agg_ops, (1 + n_agg_ops + n_columns_per_table))   \n",
    "    \n",
    "    # condcols\n",
    "    slotwise_report['condcols'] = get_metrics_cm_for_one_slot(metrics_df, (1 + n_agg_ops + n_columns_per_table),\n",
    "                                                              (1 + n_agg_ops + 2 * n_columns_per_table))  \n",
    "    # condops\n",
    "    slotwise_report['condops'] = get_metrics_cm_for_one_slot(metrics_df, (1 + n_agg_ops + 2 * n_columns_per_table),\n",
    "                                                              (1 + n_agg_ops + 2 * n_columns_per_table + n_cond_ops)) \n",
    "        \n",
    "    # condval\n",
    "    slotwise_report['condval'] = get_metrics_cm_for_one_slot(metrics_df, (1 + n_agg_ops + 2 * n_columns_per_table + n_cond_ops),\n",
    "                                                              (1 + n_agg_ops + 2 * n_columns_per_table + n_cond_ops + n_words_per_question)) \n",
    "    \n",
    "    # end\n",
    "    slotwise_report['end'] = get_metrics_cm_for_one_slot(metrics_df, (1 + n_agg_ops + 2 * n_columns_per_table + n_cond_ops + n_words_per_question), \\\n",
    "                                                         (1 + n_agg_ops + 2 * n_columns_per_table +n_cond_ops + n_words_per_question + 1))\n",
    "    \n",
    "    return slotwise_report\n",
    "\n",
    "\n",
    "# pd.DataFrame.from_dict(slotwise_report,orient='index').to_csv('D://NLP SQL Queries//EvalMetrics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
